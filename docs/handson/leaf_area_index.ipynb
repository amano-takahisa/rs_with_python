{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCVを利用した葉面積の推定\n",
    "- [このページのJupyter Notebookファイル](https://amano-takahisa.github.io/rs_with_python/handson/leaf_area_index.ipynb)\n",
    "- [google colaboratoryで開く](https://colab.research.google.com/github/amano-takahisa/rs_with_python/blob/master/docs/handson/leaf_area_index.ipynb)\n",
    "- [画像データ](https://github.com/amano-takahisa/rs_with_python/raw/master/source/handson/data/field.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pythonで画像を扱う際に、OpenCVというライブラリがよく利用されます。\n",
    "今回はこのOpenCVを用いて、作物成長段階の指標となる葉面積を推定します。\n",
    "\n",
    "まずはOpenCVモジュールを読み込みます。\n",
    "以下のチャンクを実行すると、今動いているPythonの環境にOpenCVの機能が追加されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作業しているパソコンにOpenCVがインストールされていない場合は、エラーが出ますので、以下のコマンドでインストールして、再度実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "うまくインストールされれば、以下のコマンドでバージョンが表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCVでの画像の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは画像ファイルをJupyter Notebookに読み込んで表示してみましょう。\n",
    "\n",
    "画像は、`.ipynb`ファイルと同じフォルダに`data`という名前のフォルダを作成し、その中に保存してください。以下では、[www.pxfuel.com](https://www.pxfuel.com/en/free-photo-qhhuu)から取得した画像を利用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルへのパスをimage_path変数に代入する。\n",
    "image_path = 'data/field.jpg'\n",
    "\n",
    "# 画層をOpenCVのimage形式で読み込む\n",
    "img = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のチャンクを実行すると、**image**という名前の別ウィンドウが立ち上がり、画像が表示されます。(Jupyter labをWSL2上やGoogle Colaboratoryで動かしている場合、下のコードは機能しないかもしれません。参考:[Can't use X-Server in WSL 2](https://github.com/microsoft/WSL/issues/4106))\n",
    "\n",
    "表示されたウィンドウは、キーボードのいづれかのキーを押して閉じてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV のimshow関数で、画像を表示する\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "うまく実行されれば別ウィンドウで次の画像が表示されます。\n",
    "\n",
    "![field](https://github.com/amano-takahisa/rs_with_python/raw/master/source/handson/data/field.jpg)\n",
    "\n",
    "表示されたウィンドウを閉じてもセルの番号が`[*]`と表示されたままの場合は、Jupyter NotebookメニューのKernel -> Restart Kernelで、カーネルを再起動してください。  \n",
    "\n",
    "画像の表示はこの方法でもいいですが、**matplotlib**というライブラリを利用して、Jupyter Notebook内にインラインで表示させる下記の方法がよく用いられます。\n",
    "\n",
    "まずはmatplotlibをインポートします。(必要であればmatplotlibを`!pip install matplotlib` からインストールしてください。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、`matplotlib`ライブラリ内の`pyploy`というサブモジュールを`plt`という別名でインポートしました。このように別名を使ってインポートすることにより、たとえば`matplotlib.pyplot.imshow()`と書く代わりに、`plt.imshow()`と書くことができるようになります。\n",
    "\n",
    "import文はプログラムの一番最初にまとめて記述することが慣例ですが、ここでは必要になる箇所で適宜宣言することにします。\n",
    "\n",
    "では、`matplotlib`の`matshow`関数を使って画像を表示しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "色が変ですね。\n",
    "\n",
    "これは、OpenCVとmatplotlibでのデフォルトのRGBチャンネルの順序が異なるため、赤と青が入れ替わってしまっているからです。  \n",
    "OpenCVはBGRの順、matplotlibはRGBの順でカラーを取り扱います。\n",
    "正しく読み込むには以下のように読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画層をRGBの順で読み込む\n",
    "img_bgr = cv2.imread(image_path)\n",
    "\n",
    "# cvtColor() 関数でBGRからRGBへ変換する\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "# matplotlibで表示\n",
    "plt.matshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.jpg`ファイルとして保存された写真をPythonで表示することができました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像データとはなにか\n",
    "写真や衛星画像のようなデータはラスタデータと呼ばれ、一定の間隔で格子状に区切られた各グリッドに値をもったデータ形式です。それぞれのグリッドのことをピクセルと呼ぶので、ピクセルデータと呼ぶこともあります。上で画像をプロットした際に、X軸とY軸に数値が振られていますが、この数値が画像のピクセルを表しています。通常左上を起点とした座標で表されます。  \n",
    "ラスタデータと対になるデータはベクタデータです。分野によっては、ベクタデータは、ベクトル、ポリゴンなどとも呼ばれます。\n",
    "\n",
    "詳しくはESRIのサイトに解説があるので、参考にしてください。\n",
    "\n",
    "- [ベクターデータとは: www.esrij.com](https://www.esrij.com/gis-guide/gis-datamodel/vector-data/)\n",
    "- [ラスターデータとは: wwww.esrij.com](https://www.esrij.com/gis-guide/gis-datamodel/raster-data/)\n",
    "\n",
    "今回読み込んだ画像はラスタデータです。ここではPythonの中でどのように保存されているかを見ていきます。\n",
    "\n",
    "まずは`cv2.imread()`で読み込んだ`img_bgr`を`print()`関数を用いて表示させてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_bgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print()`関数によって、画像の中のデータが表示されました。画像データは、整数の値が入ったリストが入れ子になった構造をしていることがわかります。\n",
    "\n",
    "`type()`関数で、データ型を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img_bgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`img_bgr`の実態は、`numpy.ndarray`クラスのデータであることが分かりました。\n",
    "`numpy.ndarray`クラスは、`shape`プロパティを持つので、これを確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実は、OpenCVで読みこんんだデータは、各ピクセルにおける輝度が`[青、緑、赤]`の順で保存され、その各ピクセルの値は、画像の左上から右上、さらに上から下の順で3重の入れ子構造で保存されています。そのため、`shape`を確認することで、読み込んだ画像は高さ853ピクセル、幅1280ピクセルのサイズで、3チャンネルの画像であったことがわかりました。\n",
    "\n",
    "今回の画像の例では、`print()`関数で一行目に表示された`[ 71 205 152]`の値は、左上のピクセルの青色の値が`71`、緑色が`205`、赤色が`152`の値を持っています。値が大きいほど、ディスプレイ上でその色が明るく光るので、このピクセルは緑>赤>青の順の強さで光って、黄緑色であることが推測できます。\n",
    "\n",
    "`cv2.cvtColor()`関数で変換された`img_rgb`のデータと比べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv2.cvtColor()`によって、赤色の値と青色の値が入れ替えられたことが確認できます。\n",
    "\n",
    "また、`numpy.array`は以下のようにすることで、データの一部を取り出すことができます。\n",
    "\n",
    "```Python\n",
    "array[1軸目の範囲, 2軸目の範囲, 3軸目の範囲, ...]\n",
    "```\n",
    "\n",
    "今回の画像データは縦、横、色チャンネルの3次元データです。左上の縦100x横200ピクセルに対応する`img_rgb`は次のように取り出すことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb[0:100, 0:200, :]  # 3軸目の範囲\":\" は\"すべての範囲\"を意味する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この部分だけをプロットしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_rgb[0:100, 0:200, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の左上あたりが切り取られていることが確認できました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チャンネルの分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = cv2.split(img_rgb)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(r, cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [img_rgb, r, g, b]\n",
    "colors = (None, 'Reds','Greens','Blues')\n",
    "titles = ('Original', 'Red channel', 'Green channel', 'Blue channel')\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12,3))  # figとaxを作成\n",
    "for idx, (title, channel, color) in enumerate(zip(titles, channels, colors)):\n",
    "    axs[idx].set_title(title)\n",
    "    ax = axs[idx].matshow(channel, cmap=color)\n",
    "    axs[idx].xaxis.tick_bottom()    \n",
    "    if color:\n",
    "        fig.colorbar(ax, ax=axs[idx], fraction=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSVへの変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "img_hsv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = h, s, v = cv2.split(img_hsv)\n",
    "channels.insert(0, img_rgb)\n",
    "colors = (None, 'hsv','Greys','Greys')\n",
    "titles = ('Original', 'Hue', 'Saturation', 'Value')\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12,3))  # figとaxを作成\n",
    "for idx, (title, channel, color) in enumerate(zip(titles, channels, colors)):\n",
    "    axs[idx].set_title(title)\n",
    "    ax = axs[idx].matshow(channel, cmap=color)\n",
    "    axs[idx].xaxis.tick_bottom()    \n",
    "    if color:\n",
    "        fig.colorbar(ax, ax=axs[idx], fraction=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ある地点のピクセル値を取得する\n",
    "x=999\n",
    "y=200\n",
    "img_rgb[y, x, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複数地点のピクセル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 閾値による分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_min = 150\n",
    "g_max = 250\n",
    "img_bin = (g_min < g) & (g < g_max) * 1\n",
    "# plt.imshow(img_bin, cmap='binary_r')\n",
    "plt.matshow(img_bin, cmap='binary_r')\n",
    "plt.colorbar(ticks=[0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_min = 40\n",
    "h_max = 60\n",
    "img_bin = (h_min < h) & (h < h_max) * 1\n",
    "plt.matshow(img_bin, cmap='binary_r')\n",
    "plt.colorbar(ticks=[0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mask ratio is {img_bin.sum()/img_bin.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def plot_3d(img, sampling=1000, mask=None, **kwargs):\n",
    "    xlab, ylab, zlab = 'R', 'G', 'B'\n",
    "    y,x,z = img.shape\n",
    "    img_flat = np.reshape(img, (x*y,z))\n",
    "    if mask is not None:\n",
    "        mask_flat = np.reshape(mask, (x*y)).astype('bool')\n",
    "        img_flat = img_flat[mask_flat, :]\n",
    "        \n",
    "    if sampling != 0:\n",
    "        # random sample \n",
    "        img_flat = img_flat[np.random.choice(len(img_flat), sampling, replace=False)]\n",
    "    colors = img_flat / 255\n",
    "    fig = plt.figure(**kwargs)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xs=img_flat[:,0],\n",
    "               ys=img_flat[:,1],\n",
    "               zs=img_flat[:,2],\n",
    "               s=10,\n",
    "               c=colors,\n",
    "               lw=0)\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_zlabel(zlab)\n",
    "    plt.show()\n",
    "\n",
    "# matplotlibのインタラクティブプロットを有効化\n",
    "# うまく行かない場合はコメントアウトしてください。\n",
    "# %matplotlib widget\n",
    "\n",
    "plot_3d(img = img_rgb,\n",
    "        mask=img_bin,\n",
    "        sampling=1000,\n",
    "        figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インタラクティブを無効化\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を以下のツールを利用してラベル付けをします。  \n",
    "https://github.com/yuyu2172/image-labelling-tool  \n",
    "ラベルは`json`形式のファイルに保存されます。以下で、jsonファイルをバイナリラスタに変換していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, Javascript\n",
    "from image_labelling_tool import labelling_tool, labelling_tool_jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Javascript(labelling_tool_jupyter.LABELLING_TOOL_JUPYTER_JS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify our 3 label classes.\n",
    "# `LabelClass` parameters are: symbolic name, human readable name for UI, and RGB colour as list\n",
    "label_classes = [labelling_tool.LabelClass('plant', 'Plant', [0, 255, 192]),\n",
    "                 labelling_tool.LabelClass('soil', 'Soil', [255, 128, 0])]\n",
    "\n",
    "# Define the tool dimensions\n",
    "TOOL_WIDTH, TOOL_HEIGHT = 980, 480\n",
    "\n",
    "# Load in .JPG images from the 'images' directory.\n",
    "labelled_images = labelling_tool.PersistentLabelledImage.for_directory('data', image_filename_pattern='*.jpg')\n",
    "print('Loaded {0} images'.format(len(labelled_images)))\n",
    "\n",
    "labelling_tool_config = {\n",
    "    'tools': {\n",
    "        'imageSelector': True,\n",
    "        'labelClassSelector': True,\n",
    "        'drawPolyLabel': True,\n",
    "        'compositeLabel': True,\n",
    "        'deleteLabel': True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the labelling tool IPython widget and display it\n",
    "# labeller = labelling_tool_jupyter.ImageLabellingTool(labelled_images=labelled_images, label_classes=label_classes,\n",
    "#                                                      tool_width=TOOL_WIDTH, tool_height=TOOL_HEIGHT,\n",
    "#                                                     labelling_tool_config=labelling_tool_config)\n",
    "# \n",
    "# display(labeller)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_img = labelled_images[1]\n",
    "labels_2d = labelled_img.render_labels(label_classes=['plant','soil'], pixels_as_vectors=False)\n",
    "plt.imshow(labels_2d, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/field_2__labels.json') as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_plant = [l for l in data['labels'] if l['label_class'] == 'plant']\n",
    "label_soil = [l for l in data['labels'] if l['label_class'] == 'soil']\n",
    "print(f'plant: {len(label_plant)}\\nsoil: {len(label_soil)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
